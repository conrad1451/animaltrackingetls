# catch_duplicates_script.py

# CHQ: Generated by Gemini AI

import psycopg2

import os
# import time
# import logging
# import requests
# import json
# import pandas as pd
# from dateutil.parser import parse as parse_date
# from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type
# import calendar
# import math

from sqlalchemy import create_engine

# --- Neon Database Configuration (READ FROM ENVIRONMENT VARIABLES) ---
# Ensure these environment variables are set in your GitHub Actions secrets or local environment
NEON_DB_HOST = os.getenv('NEON_DB_HOST')
NEON_DB_NAME = os.getenv('NEON_DB_NAME')
NEON_DB_USER = os.getenv('NEON_DB_USER')
NEON_DB_PASSWORD = os.getenv('NEON_DB_PASSWORD')
NEON_DB_PORT = os.getenv('NEON_DB_PORT', '5432')


POSTGRES_CONNECTION_STRING=os.getenv('POSTGRES_CONNECTION_STRING')

# conn_string = (
#     f"postgresql+psycopg2://{NEON_DB_USER}:{NEON_DB_PASSWORD}@"
#     f"{NEON_DB_HOST}:{NEON_DB_PORT}/{NEON_DB_NAME}"
# )
conn_string = (
    f"{POSTGRES_CONNECTION_STRING}"
)
# engine = create_engine(conn_string)

# Connect to your database
conn = psycopg2.connect(conn_string)
cur = conn.cursor()

# Part 1: Get the column names
cur.execute("""
    SELECT COLUMN_NAME
    FROM INFORMATION_SCHEMA.COLUMNS
    WHERE TABLE_NAME = 'june272025'
    ORDER BY ORDINAL_POSITION;
""")
columns = [row[0] for row in cur.fetchall()]



# Part 2: Construct and execute the dynamic query
column_list = ", ".join(columns)
dynamic_query = f"""
    SELECT
        {column_list},
        COUNT(*) AS duplicate_count
    FROM
        june272025
    GROUP BY
        {column_list}
    HAVING
        COUNT(*) > 1;
"""
cur.execute(dynamic_query)
duplicate_rows = cur.fetchall()

print("The following rows are duplicate rows")
 
if ( len(duplicate_rows) == 0):
     print("No duplicate rows!")

# Process your results
for row in duplicate_rows:
    print(row)


cur.close()
conn.close()